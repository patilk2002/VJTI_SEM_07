{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **NLP Lab Assignment - 02**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Aim :** Accept the Sentence as input and display Part of Speech Tags for the\n",
        "same. Also Perform dependency parsing and list out all dependency relations\n",
        "along with their operands/entities.\n",
        "\n",
        "**Name :** Kiran Patil\n",
        "\n",
        "**ID :** 211070904\n"
      ],
      "metadata": {
        "id": "iLs1-3pngJFq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CC coordinating conjunction<br>\n",
        "CD cardinal digit <br>\n",
        "DT determiner<br>\n",
        "EX existential there (like: “there is” … think of it like “there exists”)<br>\n",
        "FW foreign word <br>\n",
        "IN preposition/subordinating conjunction <br>\n",
        "JJ adjective – ‘big’ <br>\n",
        "JJR adjective, comparative – ‘bigger’<br>\n",
        "JJS adjective, superlative – ‘biggest’ <br>\n",
        "LS list marker 1) <br>\n",
        "MD modal – could, will <br>\n",
        "NN noun, singular ‘- desk’ <br>\n",
        "NNS noun plural – ‘desks’ <br>\n",
        "NNP proper noun, singular – ‘Harrison’ <br>\n",
        "NNPS proper noun, plural – ‘Americans’ <br>\n",
        "PDT predeterminer – ‘all the kids’ <br>\n",
        "POS possessive ending parent’s <br>\n",
        "PRP personal pronoun –  I, he, she <br>\n",
        "PRP\\$ possessive pronoun – my, his, hers <br>\n",
        "RB adverb – very, silently, <br>\n",
        "RBR adverb, comparative – better <br>\n",
        "RBS adverb, superlative – best <br>\n",
        "RP particle – give up <br>\n",
        "TO – to go ‘to’ the store.<br>\n",
        "UH interjection – errrrrrrrm <br>\n",
        "VB verb, base form – take <br>\n",
        "VBD verb, past tense – took <br>\n",
        "VBG verb, gerund/present participle – taking <br>\n",
        "VBN verb, past participle – taken <br>\n",
        "VBP verb, sing. present, non-3d – take <br>\n",
        "VBZ verb, 3rd person sing. present – takes <br>\n",
        "WDT wh-determiner – which <br>\n",
        "WP wh-pronoun – who, what <br>\n",
        "WP$ possessive wh-pronoun, eg- whose <br>\n",
        "WRB wh-adverb, eg- where, when<br>\n"
      ],
      "metadata": {
        "id": "BAoyBBLN5G6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install nltk"
      ],
      "metadata": {
        "id": "xtld185L4S4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('dependency_treebank')"
      ],
      "metadata": {
        "id": "TaiY6emy4iUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c93704bf-577f-4f47-f8bf-47754ae7993f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package dependency_treebank to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/dependency_treebank.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "text = \"The quick brown fox jumping over the lazy dog\"\n",
        "\n",
        "sentences = sent_tokenize(text)\n",
        "words = [word_tokenize(sentence) for sentence in sentences]"
      ],
      "metadata": {
        "id": "yjHpXbG_41I0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "\n",
        "pos_tags = [pos_tag(sentence) for sentence in words]\n",
        "\n",
        "# Print the PoS tags for each word\n",
        "for sentence_pos_tags in pos_tags:\n",
        "    print(sentence_pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcSIjUbY49Le",
        "outputId": "927e87cd-b795-42f4-ea93-c22c7db41d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumping', 'NN'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependency Parsing\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "sentence = \"The quick brown fox is jumping over the lazy dog\"\n",
        "doc = nlp(sentence)\n",
        "\n",
        "for token in doc:\n",
        "    print(\"Head: {}\\t Dependency: {}\\t Text: {}\\n\".format(str(token.head.text), str(token.dep_), str(token.text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3YYp_3k6ZF-",
        "outputId": "cc14e665-bd8e-4310-c9df-d1021d92bd76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Head: fox\t Dependency: det\t Text: The\n",
            "\n",
            "Head: fox\t Dependency: amod\t Text: quick\n",
            "\n",
            "Head: fox\t Dependency: amod\t Text: brown\n",
            "\n",
            "Head: jumping\t Dependency: nsubj\t Text: fox\n",
            "\n",
            "Head: jumping\t Dependency: aux\t Text: is\n",
            "\n",
            "Head: jumping\t Dependency: ROOT\t Text: jumping\n",
            "\n",
            "Head: jumping\t Dependency: prep\t Text: over\n",
            "\n",
            "Head: dog\t Dependency: det\t Text: the\n",
            "\n",
            "Head: dog\t Dependency: amod\t Text: lazy\n",
            "\n",
            "Head: over\t Dependency: pobj\t Text: dog\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h1oEl0HLpDiC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}